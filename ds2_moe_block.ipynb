{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3483ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`rope_scaling`'s factor field must be a float >= 1, got 40\n",
      "`rope_scaling`'s beta_fast field must be a float, got 32\n",
      "`rope_scaling`'s beta_slow field must be a float, got 1\n",
      "`rope_scaling`'s factor field must be a float >= 1, got 40\n",
      "`rope_scaling`'s beta_fast field must be a float, got 32\n",
      "`rope_scaling`'s beta_slow field must be a float, got 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce60dd04b85543b8ae5324c16d49d17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DeepseekV2ForCausalLM(\n",
       "  (model): DeepseekV2Model(\n",
       "    (embed_tokens): Embedding(102400, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0): DeepseekV2DecoderLayerTimed(\n",
       "        (self_attn): DeepseekV2Attention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (kv_a_proj_with_mqa): Linear(in_features=2048, out_features=576, bias=False)\n",
       "          (kv_a_layernorm): DeepseekV2RMSNorm((512,), eps=1e-06)\n",
       "          (kv_b_proj): Linear(in_features=512, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): DeepseekV2MLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=10944, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=10944, bias=False)\n",
       "          (down_proj): Linear(in_features=10944, out_features=2048, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): DeepseekV2RMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): DeepseekV2RMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "      (1-26): 26 x DeepseekV2DecoderLayerTimed(\n",
       "        (self_attn): DeepseekV2Attention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (kv_a_proj_with_mqa): Linear(in_features=2048, out_features=576, bias=False)\n",
       "          (kv_a_layernorm): DeepseekV2RMSNorm((512,), eps=1e-06)\n",
       "          (kv_b_proj): Linear(in_features=512, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): DeepseekV2MoE(\n",
       "          (experts): ModuleList(\n",
       "            (0-63): 64 x DeepseekV2MLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
       "              (down_proj): Linear(in_features=1408, out_features=2048, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "          )\n",
       "          (gate): DeepseekV2MoEGate()\n",
       "          (shared_experts): DeepseekV2MLP(\n",
       "            (gate_proj): Linear(in_features=2048, out_features=2816, bias=False)\n",
       "            (up_proj): Linear(in_features=2048, out_features=2816, bias=False)\n",
       "            (down_proj): Linear(in_features=2816, out_features=2048, bias=False)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): DeepseekV2RMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): DeepseekV2RMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): DeepseekV2RMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): DeepseekV2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=102400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common import init_timer_registry\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from ds2_v1 import DeepseekV2DecoderLayerTimed as v1_layer\n",
    "import transformers.models.deepseek_v2.modeling_deepseek_v2 as ds2\n",
    "ds2.DeepseekV2DecoderLayer = v1_layer\n",
    "\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-V2-Lite\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "cfg = AutoConfig.from_pretrained(model_name)\n",
    "init_timer_registry(\n",
    "    num_layers=cfg.num_hidden_layers, keep_history=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"cuda:0\"\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc65064e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[100000,  55377,    254,   4662,  20881]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\"explain the qwen\"]\n",
    "tokenizer.padding_side = \"left\"\n",
    "input_001 = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "\n",
    "input_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adceda97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Per-layer (ms) ===\n",
      "layer\tattn(PF)\t\tmlp(PF)\t\tgating(PF)\t\tsoftmax(PF)\t\texpert(PF)\t\tnorm(PF)\t\trouter(PF)\t\tdispatch(PF)\t\tcompute(PF)\t\taggregate(PF)\t||\tattn(DEC)\t\tmlp(DEC)\t\tgating(DEC)\t\tsoftmax(DEC)\t\texpert(DEC)\t\tnorm(DEC)\t\trouter(DEC)\t\tdispatch(DEC)\t\tcompute(DEC)\t\taggregate(DEC)\n",
      "L00\t0.437\t\t0.127\t\t0.000\t\t0.000\t\t0.000\t\t0.071\t\t0.000\t\t0.000\t\t0.000\t\t0.000\t||\t50.131\t\t15.317\t\t0.000\t\t0.000\t\t0.000\t\t8.372\t\t0.000\t\t0.000\t\t0.000\t\t0.000\n",
      "L01\t0.360\t\t3.123\t\t0.000\t\t0.000\t\t2.945\t\t0.063\t\t0.079\t\t13.769\t\t175.776\t\t8.186\t||\t41.158\t\t225.238\t\t0.000\t\t0.000\t\t211.435\t\t7.790\t\t9.062\t\t0.000\t\t0.000\t\t0.000\n",
      "L02\t0.381\t\t3.084\t\t0.000\t\t0.000\t\t2.960\t\t0.067\t\t0.085\t\t13.115\t\t174.854\t\t7.972\t||\t44.554\t\t222.859\t\t0.000\t\t0.000\t\t209.244\t\t7.956\t\t8.990\t\t0.000\t\t0.000\t\t0.000\n",
      "L03\t0.379\t\t3.179\t\t0.000\t\t0.000\t\t3.061\t\t0.069\t\t0.079\t\t13.163\t\t175.215\t\t7.989\t||\t44.418\t\t223.309\t\t0.000\t\t0.000\t\t209.665\t\t7.998\t\t9.024\t\t0.000\t\t0.000\t\t0.000\n",
      "L04\t0.389\t\t2.783\t\t0.000\t\t0.000\t\t2.668\t\t0.066\t\t0.077\t\t12.988\t\t175.777\t\t7.972\t||\t44.452\t\t223.904\t\t0.000\t\t0.000\t\t210.403\t\t7.876\t\t8.892\t\t0.000\t\t0.000\t\t0.000\n",
      "L05\t0.383\t\t2.891\t\t0.000\t\t0.000\t\t2.776\t\t0.064\t\t0.078\t\t12.984\t\t174.555\t\t7.947\t||\t44.505\t\t222.406\t\t0.000\t\t0.000\t\t208.877\t\t7.931\t\t8.938\t\t0.000\t\t0.000\t\t0.000\n",
      "L06\t0.390\t\t3.085\t\t0.000\t\t0.000\t\t2.968\t\t0.065\t\t0.080\t\t12.975\t\t174.554\t\t7.936\t||\t44.448\t\t222.279\t\t0.000\t\t0.000\t\t208.712\t\t7.961\t\t8.948\t\t0.000\t\t0.000\t\t0.000\n",
      "L07\t0.370\t\t2.721\t\t0.000\t\t0.000\t\t2.609\t\t0.064\t\t0.076\t\t12.973\t\t174.673\t\t7.974\t||\t44.513\t\t222.763\t\t0.000\t\t0.000\t\t209.267\t\t7.937\t\t8.898\t\t0.000\t\t0.000\t\t0.000\n",
      "L08\t0.379\t\t2.617\t\t0.000\t\t0.000\t\t2.502\t\t0.067\t\t0.078\t\t12.922\t\t174.488\t\t7.933\t||\t44.342\t\t222.683\t\t0.000\t\t0.000\t\t209.122\t\t8.010\t\t8.932\t\t0.000\t\t0.000\t\t0.000\n",
      "L09\t0.385\t\t2.940\t\t0.000\t\t0.000\t\t2.824\t\t0.066\t\t0.078\t\t12.908\t\t174.708\t\t7.912\t||\t44.430\t\t222.550\t\t0.000\t\t0.000\t\t208.952\t\t7.883\t\t8.954\t\t0.000\t\t0.000\t\t0.000\n",
      "L10\t0.393\t\t2.776\t\t0.000\t\t0.000\t\t2.658\t\t0.067\t\t0.080\t\t12.971\t\t175.020\t\t7.953\t||\t44.336\t\t222.997\t\t0.000\t\t0.000\t\t209.527\t\t7.972\t\t8.852\t\t0.000\t\t0.000\t\t0.000\n",
      "L11\t0.392\t\t2.879\t\t0.000\t\t0.000\t\t2.758\t\t0.066\t\t0.083\t\t12.928\t\t174.354\t\t7.880\t||\t44.192\t\t222.008\t\t0.000\t\t0.000\t\t208.538\t\t7.862\t\t8.860\t\t0.000\t\t0.000\t\t0.000\n",
      "L12\t0.383\t\t3.021\t\t0.000\t\t0.000\t\t2.906\t\t0.064\t\t0.078\t\t12.930\t\t174.687\t\t7.917\t||\t44.071\t\t222.226\t\t0.000\t\t0.000\t\t208.722\t\t7.983\t\t8.904\t\t0.000\t\t0.000\t\t0.000\n",
      "L13\t0.387\t\t3.076\t\t0.000\t\t0.000\t\t2.960\t\t0.069\t\t0.078\t\t13.003\t\t175.170\t\t7.915\t||\t44.186\t\t223.070\t\t0.000\t\t0.000\t\t209.474\t\t8.030\t\t8.983\t\t0.000\t\t0.000\t\t0.000\n",
      "L14\t0.376\t\t2.919\t\t0.000\t\t0.000\t\t2.795\t\t0.068\t\t0.085\t\t12.932\t\t174.284\t\t7.903\t||\t44.409\t\t222.072\t\t0.000\t\t0.000\t\t208.563\t\t7.940\t\t8.939\t\t0.000\t\t0.000\t\t0.000\n",
      "L15\t0.382\t\t2.936\t\t0.000\t\t0.000\t\t2.820\t\t0.065\t\t0.077\t\t12.985\t\t174.917\t\t7.902\t||\t44.274\t\t222.584\t\t0.000\t\t0.000\t\t209.143\t\t7.849\t\t8.873\t\t0.000\t\t0.000\t\t0.000\n",
      "L16\t0.380\t\t2.858\t\t0.000\t\t0.000\t\t2.728\t\t0.065\t\t0.091\t\t13.025\t\t175.855\t\t7.959\t||\t44.142\t\t223.846\t\t0.000\t\t0.000\t\t210.379\t\t7.919\t\t8.851\t\t0.000\t\t0.000\t\t0.000\n",
      "L17\t0.386\t\t2.934\t\t0.000\t\t0.000\t\t2.817\t\t0.065\t\t0.080\t\t12.950\t\t174.290\t\t7.882\t||\t44.331\t\t222.153\t\t0.000\t\t0.000\t\t208.639\t\t7.917\t\t8.906\t\t0.000\t\t0.000\t\t0.000\n",
      "L18\t0.373\t\t3.064\t\t0.000\t\t0.000\t\t2.951\t\t0.064\t\t0.076\t\t12.995\t\t174.811\t\t7.904\t||\t44.158\t\t222.596\t\t0.000\t\t0.000\t\t209.021\t\t7.964\t\t8.979\t\t0.000\t\t0.000\t\t0.000\n",
      "L19\t0.377\t\t2.922\t\t0.000\t\t0.000\t\t2.807\t\t0.064\t\t0.077\t\t13.030\t\t174.624\t\t7.885\t||\t44.379\t\t222.778\t\t0.000\t\t0.000\t\t208.932\t\t7.887\t\t8.990\t\t0.000\t\t0.000\t\t0.000\n",
      "L20\t0.374\t\t2.925\t\t0.000\t\t0.000\t\t2.802\t\t0.072\t\t0.085\t\t12.974\t\t174.660\t\t7.953\t||\t44.506\t\t222.554\t\t0.000\t\t0.000\t\t209.068\t\t7.948\t\t8.895\t\t0.000\t\t0.000\t\t0.000\n",
      "L21\t0.389\t\t2.758\t\t0.000\t\t0.000\t\t2.643\t\t0.067\t\t0.077\t\t12.956\t\t174.041\t\t7.937\t||\t44.594\t\t222.002\t\t0.000\t\t0.000\t\t208.500\t\t7.944\t\t8.889\t\t0.000\t\t0.000\t\t0.000\n",
      "L22\t0.403\t\t2.697\t\t0.000\t\t0.000\t\t2.580\t\t0.066\t\t0.080\t\t12.998\t\t177.678\t\t7.934\t||\t44.170\t\t225.586\t\t0.000\t\t0.000\t\t212.188\t\t7.840\t\t8.831\t\t0.000\t\t0.000\t\t0.000\n",
      "L23\t0.375\t\t2.632\t\t0.000\t\t0.000\t\t2.517\t\t0.065\t\t0.077\t\t13.011\t\t174.507\t\t7.881\t||\t44.135\t\t222.663\t\t0.000\t\t0.000\t\t209.134\t\t7.895\t\t8.956\t\t0.000\t\t0.000\t\t0.000\n",
      "L24\t0.385\t\t2.916\t\t0.000\t\t0.000\t\t2.801\t\t0.065\t\t0.078\t\t12.939\t\t174.843\t\t7.895\t||\t44.127\t\t222.735\t\t0.000\t\t0.000\t\t209.231\t\t7.938\t\t8.918\t\t0.000\t\t0.000\t\t0.000\n",
      "L25\t0.375\t\t2.699\t\t0.000\t\t0.000\t\t2.582\t\t0.063\t\t0.078\t\t12.894\t\t174.716\t\t7.886\t||\t44.412\t\t222.602\t\t0.000\t\t0.000\t\t209.145\t\t7.882\t\t8.915\t\t0.000\t\t0.000\t\t0.000\n",
      "L26\t0.393\t\t3.068\t\t0.000\t\t0.000\t\t2.953\t\t0.072\t\t0.076\t\t12.982\t\t174.601\t\t7.893\t||\t44.357\t\t222.219\t\t0.000\t\t0.000\t\t208.721\t\t7.940\t\t8.911\t\t0.000\t\t0.000\t\t0.000\n",
      "\n",
      "=== Totals (ms) ===\n",
      "attn    prefill=10.378 ms\tdecode=1199.732 ms\tall=1210.110 ms\n",
      "mlp     prefill=75.630 ms\tdecode=5809.999 ms\tall=5885.629 ms\n",
      "gating  prefill=0.000 ms\tdecode=0.000 ms\tall=0.000 ms\n",
      "softmax prefill=0.000 ms\tdecode=0.000 ms\tall=0.000 ms\n",
      "expert  prefill=72.390 ms\tdecode=5442.603 ms\tall=5514.993 ms\n",
      "norm    prefill=1.789 ms\tdecode=214.423 ms\tall=216.212 ms\n",
      "router  prefill=2.064 ms\tdecode=232.089 ms\tall=234.153 ms\n",
      "dispatch prefill=338.300 ms\tdecode=0.000 ms\tall=338.300 ms\n",
      "compute prefill=4547.659 ms\tdecode=0.000 ms\tall=4547.659 ms\n",
      "aggregate prefill=206.302 ms\tdecode=0.000 ms\tall=206.302 ms\n",
      "\n",
      "mlp_ratio_over_(attn+mlp) = 80.49%\n",
      "\n",
      "(Notes) prefill=首段批量计算；decode=逐token阶段（利用 KV cache）。\n",
      "Timing is device-side via CUDA events; each segment synchronized at stop for accuracy.\n"
     ]
    }
   ],
   "source": [
    "import common\n",
    "import torch\n",
    "# warm up\n",
    "\n",
    "common.warmup_model(model, tokenizer, text_list, 10)\n",
    "\n",
    "init_timer_registry(model.config.num_hidden_layers, keep_history=True)\n",
    "with torch.no_grad():\n",
    "    _ = model.generate(**input_001, max_new_tokens=128)  # decode\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 打印结果\n",
    "common.print_timers_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen-moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
