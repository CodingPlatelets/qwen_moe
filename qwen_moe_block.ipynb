{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c580b1",
   "metadata": {},
   "source": [
    "## qwen MOE trace and analysis module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ca178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import datasets\n",
    "# from datasets import load_dataset\n",
    "# data_id = \"wikimedia/wikipedia\"\n",
    "# sub_set_id = \"20231101.zh-classical\"\n",
    "# split = \"train\"\n",
    "# dataset = load_dataset(data_id, sub_set_id, split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6d8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_v1 import Qwen3MoeDecoderLayerTimed as v1Timed\n",
    "from qwen_v2 import Qwen3MoeDecoderLayerTimed as v2Timed\n",
    "\n",
    "version = 'v2'\n",
    "\n",
    "def modify_qwen3_moe_block(type__: str):\n",
    "    from transformers.models.qwen3_moe import modeling_qwen3_moe as qmoe\n",
    "    if type__ == 'v1':\n",
    "        qmoe.Qwen3MoeDecoderLayer = v1Timed\n",
    "    elif type__ == 'v2':\n",
    "        qmoe.Qwen3MoeDecoderLayer = v2Timed\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "modify_qwen3_moe_block(\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02eeb8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b8d6ced8954e39a9b600c8086a91e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen3MoeForCausalLM(\n",
       "  (model): Qwen3MoeModel(\n",
       "    (embed_tokens): Embedding(151936, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-47): 48 x Qwen3MoeDecoderLayerTimed(\n",
       "        (self_attn): Qwen3MoeAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "          (q_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MoeSparseMoeBlockV2(\n",
       "          (gate): Linear(in_features=2048, out_features=128, bias=False)\n",
       "          (experts): ModuleList(\n",
       "            (0-127): 128 x Qwen3MoeMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (down_proj): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3MoeRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "\n",
    "# model_name = \"Qwen/Qwen3-30B-A3B-Instruct-2507\"\n",
    "model_name = \"Qwen/Qwen3-30B-A3B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "cfg = AutoConfig.from_pretrained(model_name)\n",
    "if version == 'v2':\n",
    "    from common import init_timer_registry\n",
    "    init_timer_registry(\n",
    "        num_layers=cfg.num_hidden_layers, keep_history=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"cuda:0\"\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d7f34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[94344,   279,  2804, 16948]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\"explain the qwen\"]\n",
    "tokenizer.padding_side = \"left\"\n",
    "input_001 = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "\n",
    "input_001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a3a03f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PyTorchBenchmark' from 'transformers' (/home/lkx/data/qwen_moe/.venv/lib/python3.13/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyTorchBenchmark, PyTorchBenchmarkArguments\n\u001b[32m      2\u001b[39m args = PyTorchBenchmarkArguments(models=[model_name], batch_sizes=[\u001b[32m8\u001b[39m], sequence_lengths=[\u001b[32m8\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m512\u001b[39m])\n\u001b[32m      3\u001b[39m benchmark = PyTorchBenchmark(args)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'PyTorchBenchmark' from 'transformers' (/home/lkx/data/qwen_moe/.venv/lib/python3.13/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments\n",
    "args = PyTorchBenchmarkArguments(models=[model_name], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512])\n",
    "benchmark = PyTorchBenchmark(args)\n",
    "benchmark.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21728d4a",
   "metadata": {},
   "source": [
    "## for v1 to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dfb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity\n",
    "import torch\n",
    "import qwen_v1\n",
    "# warm up\n",
    "with torch.no_grad():\n",
    "    model_output = model(**input_001, use_cache=True)\n",
    "qwen_v1.reset_timers()\n",
    "next_token = torch.argmax(model_output.logits[:, -1, :], dim=-1, keepdim=True)\n",
    "past_kv = model_output.past_key_values\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=False, with_stack=True, profile_memory=False\n",
    ") as prof:\n",
    "    with torch.no_grad():\n",
    "        _ = model(next_token, past_key_values=past_kv, use_cache=True)\n",
    "qwen_v1.show_res()\n",
    "prof.export_chrome_trace(\"trace/trace_qwen3_moe_v1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3142a5",
   "metadata": {},
   "source": [
    "## for v2 to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "894b867a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimerRegistry(num_layers=48, keep_history=True, timers={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import common\n",
    "common._TREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "846bbd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Per-layer (ms) ===\n",
      "layer\tattn(PF)\tmlp(PF)\tgating(PF)\tsoftmax(PF)\texpert(PF)\tnorm(PF)\t||\tattn(DEC)\tmlp(DEC)\tgating(DEC)\tsoftmax(DEC)\texpert(DEC)\tnorm(DEC)\n",
      "L00\t0.787\t\t6.956\t\t0.073\t\t0.126\t\t6.378\t\t0.112\t\t||\t51.640\t\t169.326\t\t5.388\t\t8.234\t\t144.154\t\t8.048\n",
      "L01\t0.682\t\t5.353\t\t0.063\t\t0.118\t\t5.017\t\t0.108\t\t||\t46.690\t\t165.724\t\t5.019\t\t8.048\t\t141.543\t\t7.813\n",
      "L02\t0.673\t\t5.904\t\t0.065\t\t0.118\t\t5.570\t\t0.118\t\t||\t46.662\t\t164.684\t\t4.871\t\t8.065\t\t141.029\t\t7.757\n",
      "L03\t0.699\t\t6.057\t\t0.066\t\t0.118\t\t5.729\t\t0.116\t\t||\t46.116\t\t163.993\t\t4.832\t\t7.933\t\t140.575\t\t7.679\n",
      "L04\t0.702\t\t5.676\t\t0.065\t\t0.118\t\t5.347\t\t0.105\t\t||\t45.916\t\t164.344\t\t4.809\t\t8.003\t\t140.856\t\t7.681\n",
      "L05\t0.710\t\t5.500\t\t0.062\t\t0.124\t\t5.170\t\t0.109\t\t||\t46.420\t\t163.145\t\t4.944\t\t7.958\t\t139.608\t\t7.704\n",
      "L06\t0.681\t\t5.712\t\t0.077\t\t0.116\t\t5.374\t\t0.105\t\t||\t46.766\t\t163.645\t\t4.796\t\t7.976\t\t140.163\t\t7.719\n",
      "L07\t0.667\t\t5.398\t\t0.069\t\t0.116\t\t5.065\t\t0.124\t\t||\t46.010\t\t162.725\t\t4.778\t\t7.965\t\t139.331\t\t7.671\n",
      "L08\t0.659\t\t5.875\t\t0.061\t\t0.117\t\t5.554\t\t0.102\t\t||\t46.039\t\t164.119\t\t4.803\t\t7.948\t\t140.589\t\t7.690\n",
      "L09\t0.665\t\t5.180\t\t0.061\t\t0.113\t\t4.863\t\t0.103\t\t||\t46.326\t\t163.651\t\t4.848\t\t8.059\t\t140.090\t\t7.687\n",
      "L10\t0.667\t\t6.058\t\t0.062\t\t0.115\t\t5.737\t\t0.105\t\t||\t45.789\t\t163.119\t\t4.772\t\t7.941\t\t139.825\t\t7.644\n",
      "L11\t0.661\t\t5.579\t\t0.062\t\t0.114\t\t5.258\t\t0.101\t\t||\t45.944\t\t163.820\t\t4.801\t\t8.039\t\t140.336\t\t7.613\n",
      "L12\t0.670\t\t5.394\t\t0.078\t\t0.118\t\t5.051\t\t0.112\t\t||\t45.848\t\t163.179\t\t4.745\t\t7.915\t\t139.861\t\t7.611\n",
      "L13\t0.666\t\t5.194\t\t0.063\t\t0.116\t\t4.871\t\t0.107\t\t||\t46.151\t\t163.543\t\t4.779\t\t8.036\t\t140.044\t\t7.700\n",
      "L14\t0.668\t\t5.775\t\t0.065\t\t0.127\t\t5.439\t\t0.106\t\t||\t45.861\t\t162.834\t\t4.748\t\t7.940\t\t139.473\t\t7.609\n",
      "L15\t0.674\t\t5.351\t\t0.063\t\t0.114\t\t5.027\t\t0.103\t\t||\t46.142\t\t163.029\t\t4.801\t\t7.956\t\t139.639\t\t7.682\n",
      "L16\t0.661\t\t5.940\t\t0.074\t\t0.116\t\t5.604\t\t0.110\t\t||\t46.023\t\t163.036\t\t4.765\t\t7.908\t\t139.728\t\t7.711\n",
      "L17\t0.656\t\t6.111\t\t0.063\t\t0.127\t\t5.774\t\t0.104\t\t||\t46.017\t\t163.143\t\t4.729\t\t7.960\t\t139.887\t\t7.554\n",
      "L18\t0.680\t\t5.169\t\t0.065\t\t0.118\t\t4.838\t\t0.116\t\t||\t45.968\t\t162.768\t\t4.851\t\t7.984\t\t139.301\t\t7.642\n",
      "L19\t0.674\t\t4.932\t\t0.066\t\t0.116\t\t4.602\t\t0.110\t\t||\t45.552\t\t161.730\t\t4.749\t\t7.904\t\t138.528\t\t7.652\n",
      "L20\t0.715\t\t5.145\t\t0.068\t\t0.118\t\t4.814\t\t0.112\t\t||\t45.736\t\t163.024\t\t4.725\t\t7.958\t\t139.775\t\t7.642\n",
      "L21\t0.662\t\t4.976\t\t0.080\t\t0.115\t\t4.638\t\t0.105\t\t||\t45.828\t\t163.064\t\t4.805\t\t7.944\t\t139.375\t\t7.661\n",
      "L22\t0.655\t\t4.727\t\t0.062\t\t0.113\t\t4.410\t\t0.104\t\t||\t45.655\t\t163.408\t\t4.786\t\t7.923\t\t140.106\t\t7.667\n",
      "L23\t0.661\t\t4.982\t\t0.064\t\t0.116\t\t4.649\t\t0.116\t\t||\t45.888\t\t163.173\t\t5.012\t\t7.983\t\t139.591\t\t7.658\n",
      "L24\t0.637\t\t4.740\t\t0.065\t\t0.116\t\t4.414\t\t0.101\t\t||\t45.647\t\t162.969\t\t4.754\t\t7.939\t\t139.564\t\t7.554\n",
      "L25\t0.670\t\t4.793\t\t0.062\t\t0.115\t\t4.460\t\t0.102\t\t||\t45.989\t\t163.340\t\t4.796\t\t7.909\t\t139.966\t\t7.650\n",
      "L26\t0.661\t\t5.132\t\t0.065\t\t0.115\t\t4.808\t\t0.108\t\t||\t46.077\t\t162.882\t\t4.771\t\t7.893\t\t139.650\t\t7.648\n",
      "L27\t0.667\t\t5.134\t\t0.062\t\t0.116\t\t4.813\t\t0.102\t\t||\t45.908\t\t163.492\t\t4.773\t\t7.946\t\t140.092\t\t7.691\n",
      "L28\t0.648\t\t5.561\t\t0.063\t\t0.115\t\t5.216\t\t0.102\t\t||\t45.823\t\t162.629\t\t4.860\t\t7.903\t\t139.209\t\t7.681\n",
      "L29\t0.658\t\t5.349\t\t0.061\t\t0.114\t\t5.031\t\t0.107\t\t||\t45.844\t\t164.717\t\t4.810\t\t8.123\t\t141.104\t\t7.682\n",
      "L30\t0.663\t\t5.687\t\t0.063\t\t0.115\t\t5.365\t\t0.108\t\t||\t45.939\t\t162.838\t\t4.791\t\t8.005\t\t139.405\t\t7.615\n",
      "L31\t0.661\t\t5.115\t\t0.062\t\t0.113\t\t4.797\t\t0.102\t\t||\t45.849\t\t161.901\t\t4.765\t\t7.922\t\t138.587\t\t7.603\n",
      "L32\t0.649\t\t5.720\t\t0.062\t\t0.114\t\t5.401\t\t0.106\t\t||\t46.021\t\t162.901\t\t4.760\t\t7.947\t\t139.564\t\t7.634\n",
      "L33\t0.652\t\t5.138\t\t0.064\t\t0.115\t\t4.814\t\t0.119\t\t||\t45.892\t\t163.076\t\t4.755\t\t7.915\t\t139.763\t\t7.634\n",
      "L34\t0.642\t\t5.689\t\t0.060\t\t0.116\t\t5.371\t\t0.101\t\t||\t47.341\t\t163.352\t\t4.765\t\t7.922\t\t140.012\t\t7.622\n",
      "L35\t0.652\t\t5.344\t\t0.061\t\t0.115\t\t5.017\t\t0.100\t\t||\t46.003\t\t163.209\t\t4.787\t\t7.993\t\t139.758\t\t7.647\n",
      "L36\t0.670\t\t4.898\t\t0.065\t\t0.115\t\t4.569\t\t0.110\t\t||\t45.771\t\t162.839\t\t4.798\t\t7.983\t\t139.444\t\t7.649\n",
      "L37\t0.676\t\t4.557\t\t0.065\t\t0.116\t\t4.232\t\t0.102\t\t||\t46.085\t\t163.735\t\t4.805\t\t8.275\t\t139.973\t\t7.627\n",
      "L38\t0.676\t\t3.976\t\t0.061\t\t0.113\t\t3.672\t\t0.100\t\t||\t45.882\t\t163.937\t\t4.775\t\t7.898\t\t140.617\t\t7.708\n",
      "L39\t0.548\t\t4.520\t\t0.049\t\t0.098\t\t4.253\t\t0.086\t\t||\t46.323\t\t163.341\t\t4.851\t\t8.013\t\t139.689\t\t7.669\n",
      "L40\t0.517\t\t4.458\t\t0.049\t\t0.093\t\t4.189\t\t0.082\t\t||\t45.971\t\t163.435\t\t4.797\t\t8.034\t\t139.950\t\t7.665\n",
      "L41\t0.485\t\t4.480\t\t0.050\t\t0.090\t\t4.226\t\t0.080\t\t||\t45.819\t\t164.021\t\t4.789\t\t7.958\t\t140.602\t\t7.656\n",
      "L42\t0.491\t\t4.619\t\t0.048\t\t0.121\t\t4.338\t\t0.077\t\t||\t45.816\t\t162.929\t\t4.723\t\t7.900\t\t139.738\t\t7.597\n",
      "L43\t0.488\t\t4.152\t\t0.044\t\t0.085\t\t3.914\t\t0.077\t\t||\t46.239\t\t162.988\t\t4.743\t\t7.937\t\t139.612\t\t7.624\n",
      "L44\t0.498\t\t4.181\t\t0.051\t\t0.086\t\t3.937\t\t0.080\t\t||\t45.742\t\t162.288\t\t4.800\t\t7.929\t\t138.966\t\t7.626\n",
      "L45\t0.468\t\t4.283\t\t0.045\t\t0.083\t\t4.050\t\t0.076\t\t||\t46.047\t\t163.274\t\t4.825\t\t7.981\t\t139.753\t\t7.635\n",
      "L46\t0.483\t\t4.416\t\t0.045\t\t0.083\t\t4.182\t\t0.077\t\t||\t46.038\t\t163.024\t\t4.787\t\t8.057\t\t139.554\t\t7.640\n",
      "L47\t0.474\t\t4.646\t\t0.044\t\t0.082\t\t4.413\t\t0.078\t\t||\t46.114\t\t162.457\t\t4.769\t\t7.932\t\t139.151\t\t7.649\n",
      "\n",
      "=== Totals (ms) ===\n",
      "attn    prefill=30.625 ms\tdecode=2215.166 ms\tall=2245.792 ms\n",
      "mlp     prefill=249.532 ms\tdecode=7843.801 ms\tall=8093.333 ms\n",
      "gating  prefill=2.964 ms\tdecode=231.006 ms\tall=233.971 ms\n",
      "softmax prefill=5.371 ms\tdecode=382.896 ms\tall=388.267 ms\n",
      "expert  prefill=234.260 ms\tdecode=6717.130 ms\tall=6951.390 ms\n",
      "norm    prefill=4.899 ms\tdecode=367.900 ms\tall=372.799 ms\n",
      "\n",
      "mlp_ratio_over_(attn+mlp) = 75.55%\n",
      "\n",
      "(Notes) prefill=首段批量计算；decode=逐token阶段（利用 KV cache）。\n",
      "Timing is device-side via CUDA events; each segment synchronized at stop for accuracy.\n"
     ]
    }
   ],
   "source": [
    "import common\n",
    "import torch\n",
    "# warm up\n",
    "\n",
    "common.warmup_model(model, tokenizer, text_list, 10)\n",
    "\n",
    "init_timer_registry(model.config.num_hidden_layers, keep_history=True)\n",
    "with torch.no_grad():\n",
    "    _ = model.generate(**input_001, max_new_tokens=128)  # decode\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 打印结果\n",
    "common.print_timers_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen-moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
