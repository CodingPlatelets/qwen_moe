{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c580b1",
   "metadata": {},
   "source": [
    "## qwen MOE trace and analysis module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ca178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import datasets\n",
    "# from datasets import load_dataset\n",
    "# data_id = \"wikimedia/wikipedia\"\n",
    "# sub_set_id = \"20231101.zh-classical\"\n",
    "# split = \"train\"\n",
    "# dataset = load_dataset(data_id, sub_set_id, split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6d8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_v1 import Qwen3MoeDecoderLayerTimed as v1Timed\n",
    "from qwen_v2 import Qwen3MoeDecoderLayerTimed as v2Timed\n",
    "\n",
    "version = 'v2'\n",
    "\n",
    "def modify_qwen3_moe_block(type__: str):\n",
    "    from transformers.models.qwen3_moe import modeling_qwen3_moe as qmoe\n",
    "    if type__ == 'v1':\n",
    "        qmoe.Qwen3MoeDecoderLayer = v1Timed\n",
    "    elif type__ == 'v2':\n",
    "        qmoe.Qwen3MoeDecoderLayer = v2Timed\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "modify_qwen3_moe_block(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02eeb8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 16/16 [00:14<00:00,  1.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3MoeForCausalLM(\n",
       "  (model): Qwen3MoeModel(\n",
       "    (embed_tokens): Embedding(151936, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-47): 48 x Qwen3MoeDecoderLayerTimed(\n",
       "        (self_attn): Qwen3MoeAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "          (q_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MoeSparseMoeBlockV2(\n",
       "          (gate): Linear(in_features=2048, out_features=128, bias=False)\n",
       "          (experts): ModuleList(\n",
       "            (0-127): 128 x Qwen3MoeMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (down_proj): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3MoeRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "\n",
    "# model_name = \"Qwen/Qwen3-30B-A3B-Instruct-2507\"\n",
    "model_name = \"Qwen/Qwen3-30B-A3B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "cfg = AutoConfig.from_pretrained(model_name)\n",
    "if version == 'v2':\n",
    "    from common import init_timer_registry\n",
    "    init_timer_registry(\n",
    "        num_layers=cfg.num_hidden_layers, keep_history=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"cuda:0\"\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d7f34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[94344,   279,  2804, 16948]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\"explain the qwen\"]\n",
    "tokenizer.padding_side = \"left\"\n",
    "input_001 = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "\n",
    "input_001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21728d4a",
   "metadata": {},
   "source": [
    "## for v1 to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dfb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity\n",
    "import torch\n",
    "import qwen_v1\n",
    "# warm up\n",
    "with torch.no_grad():\n",
    "    model_output = model(**input_001, use_cache=True)\n",
    "qwen_v1.reset_timers()\n",
    "next_token = torch.argmax(model_output.logits[:, -1, :], dim=-1, keepdim=True)\n",
    "past_kv = model_output.past_key_values\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=False, with_stack=True, profile_memory=False\n",
    ") as prof:\n",
    "    with torch.no_grad():\n",
    "        _ = model(next_token, past_key_values=past_kv, use_cache=True)\n",
    "qwen_v1.show_res()\n",
    "prof.export_chrome_trace(\"trace/trace_qwen3_moe_v1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3142a5",
   "metadata": {},
   "source": [
    "## for v2 to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "894b867a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimerRegistry(num_layers=48, keep_history=True, timers={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import common\n",
    "common._TREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "846bbd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Per-layer (ms) ===\n",
      "layer\tattn(PF)\tmlp(PF)\tgating(PF)\tsoftmax(PF)\texpert(PF)\t||\tattn(DEC)\tmlp(DEC)\tgating(DEC)\tsoftmax(DEC)\texpert(DEC)\n",
      "L00\t0.869\t\t8.183\t\t0.089\t\t0.130\t\t7.635\t\t||\t25.405\t\t81.369\t\t2.720\t\t4.037\t\t68.602\n",
      "L01\t0.777\t\t6.521\t\t0.082\t\t0.148\t\t6.104\t\t||\t22.920\t\t80.188\t\t2.451\t\t3.958\t\t68.169\n",
      "L02\t0.752\t\t7.083\t\t0.089\t\t0.128\t\t6.684\t\t||\t22.606\t\t78.927\t\t2.414\t\t3.915\t\t67.211\n",
      "L03\t0.762\t\t7.364\t\t0.081\t\t0.129\t\t6.966\t\t||\t22.655\t\t79.240\t\t2.380\t\t3.947\t\t67.577\n",
      "L04\t0.837\t\t6.965\t\t0.087\t\t0.139\t\t6.542\t\t||\t22.668\t\t79.210\t\t2.372\t\t3.905\t\t67.503\n",
      "L05\t0.768\t\t6.752\t\t0.083\t\t0.127\t\t6.362\t\t||\t22.831\t\t79.252\t\t2.391\t\t3.928\t\t67.537\n",
      "L06\t0.754\t\t6.881\t\t0.079\t\t0.134\t\t6.488\t\t||\t22.663\t\t79.039\t\t2.393\t\t3.952\t\t67.296\n",
      "L07\t0.742\t\t6.616\t\t0.085\t\t0.136\t\t6.203\t\t||\t22.561\t\t79.387\t\t2.368\t\t3.947\t\t67.712\n",
      "L08\t0.757\t\t7.101\t\t0.079\t\t0.128\t\t6.715\t\t||\t22.709\t\t81.541\t\t2.370\t\t3.980\t\t69.817\n",
      "L09\t0.743\t\t6.282\t\t0.080\t\t0.126\t\t5.899\t\t||\t22.549\t\t78.926\t\t2.376\t\t3.923\t\t67.267\n",
      "L10\t0.763\t\t7.348\t\t0.077\t\t0.128\t\t6.964\t\t||\t22.706\t\t79.406\t\t2.384\t\t3.935\t\t67.664\n",
      "L11\t0.746\t\t6.698\t\t0.078\t\t0.136\t\t6.306\t\t||\t22.636\t\t79.429\t\t2.415\t\t3.978\t\t67.678\n",
      "L12\t0.764\t\t6.471\t\t0.079\t\t0.125\t\t6.088\t\t||\t22.531\t\t79.198\t\t2.344\t\t3.933\t\t67.580\n",
      "L13\t0.812\t\t6.246\t\t0.079\t\t0.128\t\t5.856\t\t||\t22.368\t\t78.934\t\t2.376\t\t3.954\t\t67.265\n",
      "L14\t0.763\t\t6.913\t\t0.082\t\t0.146\t\t6.491\t\t||\t22.572\t\t79.035\t\t2.359\t\t3.892\t\t67.393\n",
      "L15\t0.831\t\t6.459\t\t0.086\t\t0.149\t\t6.040\t\t||\t22.584\t\t78.826\t\t2.382\t\t3.927\t\t67.141\n",
      "L16\t0.753\t\t7.089\t\t0.083\t\t0.129\t\t6.696\t\t||\t22.696\t\t79.431\t\t2.395\t\t3.952\t\t67.686\n",
      "L17\t0.825\t\t7.374\t\t0.087\t\t0.138\t\t6.960\t\t||\t22.714\t\t78.820\t\t2.406\t\t3.944\t\t67.127\n",
      "L18\t0.772\t\t6.170\t\t0.081\t\t0.139\t\t5.771\t\t||\t22.486\t\t79.152\t\t2.378\t\t3.949\t\t67.409\n",
      "L19\t0.748\t\t6.003\t\t0.079\t\t0.130\t\t5.612\t\t||\t22.614\t\t78.524\t\t2.361\t\t3.904\t\t66.879\n",
      "L20\t0.750\t\t6.302\t\t0.079\t\t0.125\t\t5.922\t\t||\t22.638\t\t79.202\t\t2.376\t\t3.930\t\t67.505\n",
      "L21\t0.745\t\t6.075\t\t0.079\t\t0.129\t\t5.692\t\t||\t22.487\t\t78.564\t\t2.348\t\t3.921\t\t66.955\n",
      "L22\t0.754\t\t5.792\t\t0.085\t\t0.125\t\t5.400\t\t||\t22.449\t\t78.923\t\t2.380\t\t3.889\t\t67.297\n",
      "L23\t0.761\t\t5.923\t\t0.079\t\t0.125\t\t5.539\t\t||\t22.608\t\t78.873\t\t2.368\t\t3.921\t\t67.241\n",
      "L24\t0.765\t\t5.722\t\t0.087\t\t0.129\t\t5.328\t\t||\t22.682\t\t78.812\t\t2.367\t\t3.916\t\t67.013\n",
      "L25\t0.764\t\t5.728\t\t0.076\t\t0.126\t\t5.351\t\t||\t22.449\t\t78.986\t\t2.388\t\t3.957\t\t67.300\n",
      "L26\t0.750\t\t6.245\t\t0.081\t\t0.125\t\t5.855\t\t||\t22.505\t\t79.006\t\t2.415\t\t3.973\t\t67.178\n",
      "L27\t0.746\t\t6.229\t\t0.077\t\t0.125\t\t5.850\t\t||\t22.487\t\t79.040\t\t2.364\t\t3.905\t\t67.417\n",
      "L28\t0.769\t\t6.802\t\t0.083\t\t0.126\t\t6.411\t\t||\t22.730\t\t79.372\t\t2.416\t\t3.907\t\t67.630\n",
      "L29\t0.771\t\t6.396\t\t0.080\t\t0.126\t\t6.007\t\t||\t22.573\t\t78.735\t\t2.401\t\t3.916\t\t67.022\n",
      "L30\t0.750\t\t6.867\t\t0.086\t\t0.135\t\t6.463\t\t||\t22.582\t\t79.013\t\t2.379\t\t3.919\t\t67.308\n",
      "L31\t0.779\t\t6.262\t\t0.081\t\t0.130\t\t5.870\t\t||\t22.532\t\t78.600\t\t2.368\t\t3.914\t\t66.969\n",
      "L32\t0.798\t\t6.961\t\t0.086\t\t0.142\t\t6.542\t\t||\t22.534\t\t79.072\t\t2.397\t\t3.916\t\t67.395\n",
      "L33\t0.747\t\t6.204\t\t0.078\t\t0.130\t\t5.815\t\t||\t22.515\t\t78.697\t\t2.363\t\t3.882\t\t67.102\n",
      "L34\t0.768\t\t7.008\t\t0.078\t\t0.126\t\t6.626\t\t||\t22.600\t\t78.837\t\t2.400\t\t3.987\t\t67.058\n",
      "L35\t0.750\t\t6.395\t\t0.079\t\t0.126\t\t6.011\t\t||\t22.541\t\t79.064\t\t2.400\t\t3.969\t\t67.288\n",
      "L36\t0.746\t\t5.999\t\t0.082\t\t0.127\t\t5.615\t\t||\t22.632\t\t79.055\t\t2.361\t\t3.965\t\t67.347\n",
      "L37\t0.742\t\t5.531\t\t0.078\t\t0.126\t\t5.144\t\t||\t22.735\t\t78.939\t\t2.377\t\t3.900\t\t67.286\n",
      "L38\t0.768\t\t5.973\t\t0.081\t\t0.128\t\t5.582\t\t||\t22.658\t\t79.168\t\t2.382\t\t3.901\t\t67.517\n",
      "L39\t0.763\t\t6.945\t\t0.080\t\t0.138\t\t6.545\t\t||\t22.596\t\t78.798\t\t2.351\t\t3.894\t\t67.171\n",
      "L40\t0.779\t\t6.933\t\t0.080\t\t0.137\t\t6.531\t\t||\t22.472\t\t78.883\t\t2.397\t\t3.893\t\t67.209\n",
      "L41\t0.769\t\t7.112\t\t0.084\t\t0.132\t\t6.716\t\t||\t22.574\t\t78.753\t\t2.378\t\t3.884\t\t67.145\n",
      "L42\t0.752\t\t7.329\t\t0.084\t\t0.132\t\t6.931\t\t||\t22.636\t\t78.957\t\t2.390\t\t3.964\t\t67.245\n",
      "L43\t0.795\t\t6.866\t\t0.085\t\t0.141\t\t6.456\t\t||\t22.747\t\t78.730\t\t2.474\t\t3.938\t\t66.905\n",
      "L44\t0.754\t\t7.031\t\t0.075\t\t0.126\t\t6.651\t\t||\t22.391\t\t78.842\t\t2.334\t\t3.921\t\t67.206\n",
      "L45\t0.772\t\t7.016\t\t0.081\t\t0.135\t\t6.613\t\t||\t22.605\t\t78.786\t\t2.377\t\t3.958\t\t67.057\n",
      "L46\t0.752\t\t7.310\t\t0.077\t\t0.126\t\t6.931\t\t||\t22.646\t\t79.044\t\t2.364\t\t3.896\t\t67.305\n",
      "L47\t0.754\t\t7.909\t\t0.087\t\t0.128\t\t7.515\t\t||\t22.828\t\t78.968\t\t2.396\t\t3.909\t\t67.274\n",
      "\n",
      "=== Totals (ms) ===\n",
      "attn    prefill=36.848 ms\tdecode=1087.906 ms\tall=1124.755 ms\n",
      "mlp     prefill=319.386 ms\tdecode=3797.554 ms\tall=4116.940 ms\n",
      "gating  prefill=3.913 ms\tdecode=114.748 ms\tall=118.662 ms\n",
      "softmax prefill=6.300 ms\tdecode=188.710 ms\tall=195.011 ms\n",
      "expert  prefill=300.297 ms\tdecode=3234.860 ms\tall=3535.157 ms\n",
      "\n",
      "mlp_ratio_over_(attn+mlp) = 78.54%\n",
      "\n",
      "(Notes) prefill=首段批量计算；decode=逐token阶段（利用 KV cache）。\n",
      "Timing is device-side via CUDA events; each segment synchronized at stop for accuracy.\n"
     ]
    }
   ],
   "source": [
    "import common\n",
    "import torch\n",
    "# warm up\n",
    "\n",
    "common.warmup_model(model, tokenizer, text_list, 10)\n",
    "\n",
    "init_timer_registry(model.config.num_hidden_layers, keep_history=True)\n",
    "with torch.no_grad():\n",
    "    _ = model(**input_001)  # prefill\n",
    "    _ = model.generate(**input_001, max_new_tokens=64)  # decode\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 打印结果\n",
    "common.print_timers_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen-moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
