{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c580b1",
   "metadata": {},
   "source": [
    "## qwen MOE trace and analysis module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ca178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "from datasets import load_dataset\n",
    "data_id = \"wikimedia/wikipedia\"\n",
    "sub_set_id = \"20231101.zh-classical\"\n",
    "split = \"train\"\n",
    "dataset = load_dataset(data_id, sub_set_id, split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6d8e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwk/data/code/qwen_moe/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from v1 import Qwen3MoeDecoderLayerTimed\n",
    "\n",
    "\n",
    "def modify_qwen3_moe_block(type__: str):\n",
    "    from transformers.models.qwen3_moe import modeling_qwen3_moe as qmoe\n",
    "    if type__ == \"v1\":\n",
    "        qmoe.Qwen3MoeDecoderLayer = Qwen3MoeDecoderLayerTimed\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "modify_qwen3_moe_block(\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02eeb8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 16/16 [00:19<00:00,  1.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3MoeForCausalLM(\n",
       "  (model): Qwen3MoeModel(\n",
       "    (embed_tokens): Embedding(151936, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-47): 48 x Qwen3MoeDecoderLayerTimed(\n",
       "        (self_attn): Qwen3MoeAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "          (q_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3MoeRMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MoeSparseMoeBlockV1(\n",
       "          (gate): Linear(in_features=2048, out_features=128, bias=False)\n",
       "          (experts): ModuleList(\n",
       "            (0-127): 128 x Qwen3MoeMLP(\n",
       "              (gate_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (up_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (down_proj): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3MoeRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3MoeRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-30B-A3B-Instruct-2507\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d7f34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[94344,   279,  2804, 16948]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\"explain the qwen\"]\n",
    "tokenizer.padding_side = \"left\"\n",
    "input_001 = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "\n",
    "input_001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dfb4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-layer ms:\n",
      "L00\tattn=0.000\tmlp=0.000\texpert=0.000\tsoftmax=0.000\tgating=0.000\n",
      "L01\tattn=1.003\tmlp=9.010\texpert=8.522\tsoftmax=0.158\tgating=0.118\n",
      "L02\tattn=0.989\tmlp=10.608\texpert=10.111\tsoftmax=0.157\tgating=0.122\n",
      "L03\tattn=0.987\tmlp=10.204\texpert=9.706\tsoftmax=0.158\tgating=0.119\n",
      "L04\tattn=1.041\tmlp=10.163\texpert=9.648\tsoftmax=0.166\tgating=0.131\n",
      "L05\tattn=1.076\tmlp=11.434\texpert=10.794\tsoftmax=0.257\tgating=0.129\n",
      "L06\tattn=1.092\tmlp=7.775\texpert=7.257\tsoftmax=0.168\tgating=0.128\n",
      "L07\tattn=1.012\tmlp=9.890\texpert=9.375\tsoftmax=0.165\tgating=0.125\n",
      "L08\tattn=1.086\tmlp=9.427\texpert=8.940\tsoftmax=0.159\tgating=0.116\n",
      "L09\tattn=1.020\tmlp=9.089\texpert=8.592\tsoftmax=0.160\tgating=0.126\n",
      "L10\tattn=1.019\tmlp=11.264\texpert=10.759\tsoftmax=0.167\tgating=0.119\n",
      "L11\tattn=1.086\tmlp=10.548\texpert=9.996\tsoftmax=0.171\tgating=0.131\n",
      "L12\tattn=1.213\tmlp=11.337\texpert=10.773\tsoftmax=0.177\tgating=0.140\n",
      "L13\tattn=1.198\tmlp=10.109\texpert=9.580\tsoftmax=0.173\tgating=0.130\n",
      "L14\tattn=1.017\tmlp=10.485\texpert=9.984\tsoftmax=0.161\tgating=0.123\n",
      "L15\tattn=1.096\tmlp=10.327\texpert=9.723\tsoftmax=0.172\tgating=0.126\n",
      "L16\tattn=1.645\tmlp=10.100\texpert=9.460\tsoftmax=0.169\tgating=0.204\n",
      "L17\tattn=1.040\tmlp=9.815\texpert=9.304\tsoftmax=0.164\tgating=0.120\n",
      "L18\tattn=1.062\tmlp=8.685\texpert=8.190\tsoftmax=0.160\tgating=0.121\n",
      "L19\tattn=1.000\tmlp=7.685\texpert=7.181\tsoftmax=0.160\tgating=0.122\n",
      "L20\tattn=1.033\tmlp=8.993\texpert=8.505\tsoftmax=0.158\tgating=0.115\n",
      "L21\tattn=0.991\tmlp=8.324\texpert=7.832\tsoftmax=0.157\tgating=0.122\n",
      "L22\tattn=1.026\tmlp=9.663\texpert=9.169\tsoftmax=0.160\tgating=0.122\n",
      "L23\tattn=1.052\tmlp=8.458\texpert=7.959\tsoftmax=0.160\tgating=0.127\n",
      "L24\tattn=1.010\tmlp=9.169\texpert=8.664\tsoftmax=0.159\tgating=0.125\n",
      "L25\tattn=1.010\tmlp=8.771\texpert=8.282\tsoftmax=0.158\tgating=0.120\n",
      "L26\tattn=1.070\tmlp=9.767\texpert=9.267\tsoftmax=0.160\tgating=0.120\n",
      "L27\tattn=1.030\tmlp=8.847\texpert=8.278\tsoftmax=0.219\tgating=0.127\n",
      "L28\tattn=1.009\tmlp=9.467\texpert=8.963\tsoftmax=0.168\tgating=0.119\n",
      "L29\tattn=1.057\tmlp=9.526\texpert=8.958\tsoftmax=0.219\tgating=0.124\n",
      "L30\tattn=1.005\tmlp=10.679\texpert=10.182\tsoftmax=0.159\tgating=0.124\n",
      "L31\tattn=0.988\tmlp=8.723\texpert=8.234\tsoftmax=0.157\tgating=0.118\n",
      "L32\tattn=1.022\tmlp=9.539\texpert=9.030\tsoftmax=0.161\tgating=0.125\n",
      "L33\tattn=1.012\tmlp=10.870\texpert=8.548\tsoftmax=1.862\tgating=0.124\n",
      "L34\tattn=1.020\tmlp=9.881\texpert=9.354\tsoftmax=0.175\tgating=0.123\n",
      "L35\tattn=1.092\tmlp=9.465\texpert=8.949\tsoftmax=0.159\tgating=0.129\n",
      "L36\tattn=1.025\tmlp=8.739\texpert=8.240\tsoftmax=0.160\tgating=0.126\n",
      "L37\tattn=1.082\tmlp=8.749\texpert=8.256\tsoftmax=0.158\tgating=0.118\n",
      "L38\tattn=1.014\tmlp=9.463\texpert=8.957\tsoftmax=0.161\tgating=0.124\n",
      "L39\tattn=1.100\tmlp=10.083\texpert=9.584\tsoftmax=0.158\tgating=0.123\n",
      "L40\tattn=1.041\tmlp=10.702\texpert=10.193\tsoftmax=0.162\tgating=0.125\n",
      "L41\tattn=1.102\tmlp=11.847\texpert=11.294\tsoftmax=0.172\tgating=0.137\n",
      "L42\tattn=1.090\tmlp=10.823\texpert=10.210\tsoftmax=0.178\tgating=0.195\n",
      "L43\tattn=1.039\tmlp=9.458\texpert=8.955\tsoftmax=0.158\tgating=0.128\n",
      "L44\tattn=1.032\tmlp=9.313\texpert=8.819\tsoftmax=0.160\tgating=0.117\n",
      "L45\tattn=1.022\tmlp=10.529\texpert=10.025\tsoftmax=0.157\tgating=0.122\n",
      "L46\tattn=1.030\tmlp=10.668\texpert=10.160\tsoftmax=0.160\tgating=0.126\n",
      "L47\tattn=1.148\tmlp=12.935\texpert=12.365\tsoftmax=0.177\tgating=0.142\n",
      "summary:\n",
      "attn_total=49.832 ms\tmlp_total=461.406 ms\texpert_total=435.124 ms\tsoftmax_total=9.573 ms\tgating_total=5.995 ms\n",
      "mlp_ratio=90.3%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import v1\n",
    "# warm up\n",
    "with torch.no_grad():\n",
    "    model_output = model(**input_001)\n",
    "v1.reset_timers()\n",
    "\n",
    "from torch.profiler import profile, ProfilerActivity\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    record_shapes=True, with_stack=True, profile_memory=True\n",
    ") as prof:\n",
    "    with torch.no_grad():\n",
    "        _ = model(**input_001)\n",
    "v1.show_res()\n",
    "prof.export_chrome_trace(\"trace/trace_qwen3_moe_v1.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen-moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
